{
    "collab_server" : "",
    "contents" : "# clean working directory\n#rm(list = ls(all = TRUE))\n\n# Set working directory\nsetwd(\"~/Desktop/Final paper\")\n\n#load package\nlibrary(tidyverse)\nlibrary(lme4)\nlibrary(lmerTest)\n\n#load data\nept_df1 <- read_csv(\"./data/ept_raw.csv\") %>% \n  mutate(., groupCon = recode(group, co = 0.5, hs = -0.5), #porque 0.5?\n         freqCon = recode(frequency, f = 0.5, u = -0.5))\n\nept_df2 <- read_csv(\"./data/ept_additional_data.csv\") %>% \n  mutate(., groupCon = recode(group, co = 0.5, hs = -0.5), \n         freqCon = recode(frequency, f = 0.5, u = -0.5))\n\n\n# incorporate the df with the additional data\n\nept_df_temp <- rbind(ept_df1, ept_df2)\n\n\nverbs <- c('f1' = 'cuidar', \n           'f2' = 'encontrar', \n           'f3' = 'tocar', \n           'f4' = 'aceptar', \n           'f5' = 'medir', \n           'f6' = 'parar', \n           'f7' = 'llevar', \n           'f8' = 'cambiar',\n           'u1' = 'vigilar',\n           'u2' = 'hallar', \n           'u3' = 'acariciar', \n           'u4' = 'acoger', \n           'u5' = 'abrigar', \n           'u6' = 'detener', \n           'u7' = 'trasladar', \n           'u8' = 'reemplazar')\n\nept_df_temp$verbs <- verbs[ept_df_temp$item]\n\n\nunique(ept_df_temp$participant)\n\n\n\n\n\n# import dele data and join with df\nept_df <- read_csv(\"./data/prof_df.csv\") %>% \n  left_join(ept_df_temp, ., by = 'participant')\n\n# the new frequency counts from the Davis corpus\ncountfreq <- c('f1' = 7531,\n               'f2' = 21725 , \n               'f3' = 3861  , \n               'f4' = 4098  , \n               'f5' = 886, \n               'f6' = 8174  , \n               'f7' = 107445 , \n               'f8' = 9871,\n               'u1' = 1197 ,\n               'u2' = 803, \n               'u3' = 427 , \n               'u4' = 2423, \n               'u5' = 123 , \n               'u6' = 5912, \n               'u7' = 4402, \n               'u8' = 4252)\nept_df$countfreq <- countfreq[ept_df$item]\n\n\n# added a new column in order to plot per items as a synonim pair.\n#ept_df %>%\n#  ggplot(., aes(x = response, y = countfreq)) +\n#           geom_boxplot()\n         \n         \n#unique(ept_df_temp$participant)\n         \n#glimpse(ept_df)\n         \n#         synonym <- c('f1' = 1 , \n#                      'f2' = 2 , \n#                      'f3' = 3 , \n#                      'f4' = 4 , \n#                      'f5' = 5 , \n#                      'f6' = 6 , \n#                      'f7' = 7 , \n#                      'f8' = 8 ,\n#                      'u1' = 1 ,\n#                      'u2' = 2 , \n#                      'u3' = 3 , \n#                      'u4' = 4 , \n#                      'u5' = 5 , \n#                      'u6' = 6 , \n#                      'u7' = 7 , \n#                      'u8' = 8)\n#         ept_df$synonym <- synonym[ept_df$item]\n         \n         \n         # !!!! NO MORE OPENING THE FOLLOWING FILES:\n         # - ajt_comp_clean.csv\n         # - ajt_raw.csv\n         # - ept_comp_clean.csv\n         # - ept_raw.csv\n         \n         # proficiency\n         # - create data frame (excel) with participant ID and prof label and dele (participant, prof, dele)\n         # - save as 'prof_df.csv' in data folder\n         \n         # frequency\n         # - create data frame (excel) with verb (infinitive) and frequency (davis score)\n         # - 2 columns, verb and freq\n         # - save as 'freq_df.csv' in data folder\n         \n         # additional participants\n         # - create new data frame for additional participants\n         # - same columns as 'ajt_raw.csv' and 'ept_raw.csv'\n         # - save as 'ajt_additional_data.csv' in data folder\n         # - save as 'ept_additional_data.csv' in data folder\n         \n         \n#         ept_df %>%\n#           group_by(., proficiency) %>%\n#           summarize(.,mean_response = mean(response), sd_score = sd(response),\n#                     mean_countfreq =mean(countfreq), sd_exp = sd(countfreq)) \n\n## A tibble: 3 x 5\n#proficiency mean_response sd_score mean_countfreq sd_exp\n#   <chr>               <dbl>    <dbl>          <dbl>  <dbl>\n# 1 co                  0.996   0.0645         11446. 25369.\n# 2 hs_adv              0.441   0.497          11446. 25356.\n# 3 hs_int              0.144   0.352          11446. 25395.\n\n#ept_df %>%\n#  ggplot(., aes(x=log(countfreq), y=response, color = proficiency)) +\n#  geom_jitter(height = 0.02, width = 0.4) + \n#  geom_smooth(method = lm, se = F) + \n#  facet_grid(. ~ as.factor(synonym))\n\nept_df %>%\n  ggplot(., aes(x = factor(synonym), y = response, color = proficiency, dodge = proficiency)) +\n   stat_summary(fun.data = mean_se, geom = 'pointrange', position = position_dodge(0.5))\n\nept_elog <- ept_df %>% \n  group_by(., participant, proficiency, countfreq, groupCon, response, item) %>% \n  summarize(., n = 8, \n            wDOM = sum(response), \n            woDOM = n - wDOM, \n            eLog = log((wDOM + 0.5) / (n - wDOM + 0.5)), \n            wts = 1 / (wDOM + 0.5) + 1 / (n - wDOM + 0.5),\n            countLog = log(countfreq))\n\n\nept_elog %>% \n  ggplot(., aes(x = countLog, y = response, color = proficiency)) +\n  geom_jitter(height = 0.04, width = 0.2, alpha = 0.5) +\n  geom_smooth(method = lm, fullrange = T) +\n  scale_color_brewer(palette = \"Set1\") + \n  theme_bw()\n\n\n\nept_elog2 <- ept_elog %>%\n  filter(., !(item %in% c(\"f2\", 'f7', 'u3' ,'u5'))) \n\n\n\nept_fig1 <- ept_elog2 %>%\n  ggplot(., aes(x = countLog, y = response, color = proficiency)) +\n    geom_jitter(height = 0.04, width = 0.2, alpha = 0.5) +\n    geom_smooth(method = lm, fullrange = T) +\n    scale_color_brewer(palette = \"Set1\") \n\n\n\n\n\n\n\n#           filter(., countfreq!= \"f2\") %>%\n#             filter(., countfreq!= \"f7\") %>%\n#             filter(., countfreq!= \"f8\") %>%\n#             \n#         ept_elog %>%\n#           filter(., countfreq!= \"f2\") %>%\n#           filter(., countfreq!= \"f7\") %>%\n#           ggplot(., aes(x=countLog, y=response, color = proficiency)) +\n#           geom_hline(yintercept = 0.60205, lty = 2, size = 0.25, color = \"grey60\") + # from fitted model below\n#           geom_vline(xintercept = 0, lty = 2, size = 0.25, color = \"grey60\") +       # from fitted model below\n#           geom_point() + \n#           geom_smooth(method = lm, se = F, fullrange = T) + \n#           geom_abline(intercept = 0.60205, slope = 0.67977, lty = 3) \n\n         \n         # the plot per items\n#         ept_df %>%\n#           ggplot(., aes(x=countfreq, y=response, color = proficiency)) +\n#           geom_abline(intercept = 0.60205, slope = 0.67977, lty = 3) +\n#           geom_hline(yintercept = 0.60205, lty = 2, size = 0.25, color = \"grey60\") + # from fitted model below\n#           geom_vline(xintercept = 0, lty = 2, size = 0.25, color = \"grey60\") +       # from fitted model below\n#           geom_point() + \n#           geom_smooth(method = lm, se = F, fullrange = T) + \n#           geom_abline(intercept = 0.60205, slope = 0.67977, lty = 3) +\n#           facet_wrap( ~ synonym, nrow = 3)\n                       \n#Previous Nested Comparison Data from my QP\n#ept_elog <- ept_df %>% \n#  group_by(., participant, proficiency, countfreq, groupCon, response, item) %>% \n#  summarize(., n = 8, \n#            wDOM = sum(response), \n#            woDOM = n - wDOM, \n#            eLog = log((wDOM + 0.5) / (n - wDOM + 0.5)), \n#            wts = 1 / (wDOM + 0.5) + 1 / (n - wDOM + 0.5),\n#            countLog = log(countfreq))\n  \n\n#nested model comparison\n## GOOD\nmod_nul <- lm(eLog ~1, data = ept_elog2)\nsummary(mod_nul)\n\nmod_cat <-lm(eLog ~ countLog, data = ept_elog2)\nsummary(mod_cat)\n\nmod_con <-lm(eLog ~ countLog + proficiency, data = ept_elog2)\nsummary(mod_con)\n\nmod_int <-lm(eLog ~ countLog * proficiency, data = ept_elog2)\nsummary(mod_int)\n\nanova(mod_nul, mod_cat, mod_con, mod_int)\n\n## EPT en elog sin los verbos mas y menos frecuentes y sin controles\n\nept_elog2_hs <- ept_elog2 %>% filter(., proficiency != 'co') %>% \n  mutate(., profCon = if_else(proficiency == 'hs_adv', true = 0.5, false = -0.5))\n\nmod_nul_hs <- lm(eLog ~1, data = ept_elog2_hs)\nsummary(mod_nul)\n\nmod_cat_hs <-lm(eLog ~ countLog, data = ept_elog2_hs)\nsummary(mod_cat)\n\nmod_con_hs <-lm(eLog ~ countLog + proficiency, data = ept_elog2_hs)\nsummary(mod_con)\n\nmod_int_hs <-lm(eLog ~ countLog * proficiency, data = ept_elog2_hs)\nsummary(mod_int)\n\nanova(mod_nul_hs, mod_cat_hs, mod_con_hs, mod_int_hs)\n\n#ept_elog2_hs %>%\n#  ggplot(., aes(x = countLog, y = response, color = proficiency)) +\n#  geom_point()+\n#  geom_smooth(method =lm)+\n#  scale_color_brewer(palette = \"Set1\")\n\n\n#lm_full <- lmer(eLog ~ proficiency * countLog +\n#                  (1 | participant),\n#                data = ept_elog, weights = 1/wts, \n#                control=lmerControl(optimizer=\"bobyqa\"))\n\n\n#anova(lm_null, lm_prof, lm_full, test = 'Chisq')\n\n#summary(lm_full)\n#ranef(lm_full)\n\n#ept_elog_hs <- ept_elog %>% filter(., proficiency != 'co') %>% \n# mutate(., profCon = if_else(proficiency == 'hs_adv', true = 0.5, false = -0.5))\n\n#lm_hs <- lmer(eLog ~ countLog * profCon + \n#                (1 | participant), \n#              data = ept_elog_hs, weights = 1/wts, \n#              control = lmerControl(optimizer = 'bobyqa')) \n\n#summary(lm_hs)\n\n\n\n\n",
    "created" : 1525828004923.000,
    "dirty" : true,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "4048894828",
    "id" : "65543183",
    "lastKnownWriteTime" : 1525831308,
    "last_content_update" : 1525835533929,
    "path" : "~/Desktop/Final paper/scripts/eptdata.R",
    "project_path" : "scripts/eptdata.R",
    "properties" : {
    },
    "relative_order" : 6,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_source"
}